---
title: "Why mgcv is awesome"
author: "Chris Mainey"
date: '`r Sys.Date()`'
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
    seal: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(fig.width=10, fig.height=6, fig.align = "center", 
                      dpi = 500, dev.args = list(png = list(type = "cairo"))) 

library(Cairo)

set.seed(123)

x <- c(runif(50, 0, 5), 0)
y <- 2 + (1.5 * x) + rnorm(50, 0, 0.5)
y[51] <- 2

my_data <- data.frame(x, y)

rm(list = c('x','y'))

x <- c(2,3,3)
y <- 2 + (1.5 * x)
y[2] <- y[1]
y[3] <- y[3] +0.05

dt2 <- data.frame(x, y)

rm(list = c('x','y'))

triangle<- data.frame(x=c(2.5, 3.2, 0),
y = c(4.5, 5.8, 2.9), 
label=c("1", "1.5", "2"))



```

```{r xaringan-themer, include=FALSE}
#library(xaringanthemer)
#mono_light(base_color = "#23395b",
#           )
```

.pull-left[

<br><br><br>
<br><br><br>

# Why `mgcv` is awesome

<br><br><br>
<br><br>

`r icon::fa("envelope")` chris.mainey@uhb.nhs.uk

`r icon::fa("globe")` [mainard.co.uk](https://www.mainard.co.uk)

`r icon::fa("github")` [github.com/chrismainey](https://github.com/chrismainey)

`r icon::fa("twitter")` [twitter.com/chrismainey](https://twitter.com/chrismainey)

]

.pull-right[

<img src="man/figures/download.png">

_Don'think about it too hard..._ `r emo::ji("wink")` 

]


---

# Regression models on non-linear data

+ Regression is a common method for predicting a variable `Y` using `X`

```{r regression1, echo=FALSE, message=FALSE, warning=FALSE}
library(ggplot2)
library(ggforce)
a<-ggplot(my_data, aes(x=x,y=y))+
  geom_point()+
  scale_x_continuous(limits=c(0,5))+
  scale_y_continuous(breaks=seq(2,10,2))

a
```
---

# Equation of a straight line

$$y= \alpha + \beta x + \epsilon$$

```{r regression2, echo=FALSE, message=FALSE, warning=FALSE}
a+geom_smooth(col="red", method="lm")+
  geom_polygon(aes(x=x, y=y), col="goldenrod", fill=NA, linetype="dashed", size=1.2, data=dt2)+
  geom_label(aes(x=x, y = y, label=label), data=triangle)+
  geom_mark_circle(aes(x=0, y=2, r=0.5), col="goldenrod",  fill=NA, linetype="dashed", size=1.2)
```



--


$$y= 2 + 1.5 x + \epsilon$$

---

# What about nonlinear data? (1)

```{r sig, echo=FALSE, message=TRUE, warning=FALSE}
### Sigmoid function ### create a function to generate sigmoid pattern
sigmoid <- function(x, lower_asymptote, carrying_capacity, growth_rate, time_max) {
  return(lower_asymptote + ((carrying_capacity - lower_asymptote)/(1 + exp(-growth_rate * 
                                                                             (x - time_max)))))
}
x <- 1:100
x <- c(x, x+rnorm(x,x,2), x+rnorm(x, x, 5))
y <- sigmoid(1:100, 1, 50, 0.2, 50) + rnorm(100, 0, 5)
y <- c(y, y+rnorm(y, y, 3), y+rnorm(y, y, 8))
dt<-data.frame(x,y)

dt$cat<-factor(ifelse(dt$x<50, "a", ifelse(dt$x <150, "b", "c")))

dt$cat_pred<-predict(lm(dt$y ~ dt$cat))



ggplot(dt, aes(y=y, x=x))+
  geom_point(size=1.5, alpha=0.4)

```


---

# What about nonlinear data? (2)

```{r cats, echo=FALSE, message=FALSE, warning=FALSE, fig.height=6.5}
ggplot(dt, aes(y=y, x=x))+
  geom_point(size=1.8, alpha=0.4)+
  geom_smooth(aes(col="A"), method = "lm",  se=FALSE, size=1.2)+
  geom_line(aes(y=cat_pred, col="B"),  size=1.2)+
  geom_smooth(aes(col="C"), method = "lm", formula= y~poly(x, 3),  se=FALSE, size=1.2)+
  scale_color_manual(values = c("#5DDEDE", "#FAD74B" ,"#FA6767"),
                     labels= factor(x=c("A", "B", "C"), levels=c("A", "B", "C"), labels=c("Linear", "Categorical", "Polynomial"), ordered=TRUE)
                     , name="Type of fit")+
  #ggtitle("Varying approximations for non-linear relationships")+
  theme(legend.position = "bottom",
        legend.title = element_text(face="bold", size=10),
        legend.text = element_text(size=9),
        plot.title = element_text(size = 12, face="bold") )
```
---

# Splines

+ Smooth, piece-wise polynomials, like a flexible strip for drawing curves.
+ 'Knot points' between each section

```{r gam1, echo=FALSE, message=FALSE, warning=FALSE}
library(splines)
ggplot(dt, aes(y=y, x=x))+
  geom_point(size=1.5, alpha=0.4)+
  geom_smooth(aes(col="A"), method = "lm", formula = y~ns(x,10), se=FALSE, size=1.2, show.legend = FALSE)
```

---

# How smooth?

Can be controlled by number of knots, or by a penalty

.pull-left[
```{r knots2, echo=FALSE, message=FALSE, warning=FALSE, fig.width=5}
library(viridis)
library(mgcv)

knotplot<-factor(c("3-knots" = "#5DDEDE", "20-knots" =  "#FAD74B" , "50-knots" ="#FA6767" ), ordered = TRUE)
knotplot<-factor(c("#5DDEDE", "#FAD74B" , "#FA6767" ), labels = c("3-knots", "20-knots" , "50-knots"), ordered = TRUE)

knotplot<-c("#5DDEDE"="3", "#FAD74B"="20" ,"#FA6767"="50") 
k2<-as.factor(knotplot)

ggplot(dt, aes(y=y, x=x))+
  geom_point(size=1.5, alpha=0.4)+
   geom_smooth(aes(col="A"), method = "lm", formula = y~ns(x,4), se=FALSE, size=1.2)+
   geom_smooth(aes(col="B"), method = "lm", formula = y~ns(x,31), se=FALSE, size=1.2)+
   geom_smooth(aes(col="C"), method = "lm", formula = y~ns(x,51), se = FALSE, size=1.2)+
  scale_color_manual(values = c("#5DDEDE", "#FAD74B" ,"#FA6767"),
                     labels= factor(x=c("A", "B", "C"), levels=c("A", "B", "C"), labels=c("3", "20", "50"), ordered=TRUE)
                     , name="Knots")+

  # scale_color_discrete(#values = c("#5DDEDE", "#FAD74B" ,"#FA6767")
  #                    breaks= c("3","20","50"), name="Knots" )+
  # 
  ggtitle("Changing number of knots")+
  theme(legend.title = element_text(face="bold", size=9),
        legend.text = element_text(size=8),
        legend.position = "bottom",
        plot.title = element_text(size = 11, face="bold") )


```
]

.pull-right[
```{r penalty, echo=FALSE, message=FALSE, warning=FALSE, fig.width=5}
########### Use gam sim for sigmoid and show difference in lambda ###############

smsp<-gam(y~s(x, bs="cr", k=20), data=dt, gamma=0.001)
dt$sp1<-predict(smsp, type="response")

smsp2<-gam(y~s(x, bs="cr", k=20), data=dt, gamma = 1 )
dt$sp2<-predict(smsp2, type="response")

smsp3<-gam(y~s(x, bs="cr", k=20), data=dt, gamma = 10)
dt$sp3<-predict(smsp3, type="response")


#dt$sp1<-NULL
ggplot(dt, aes(y=y, x=x))+
  geom_point(alpha=0.4)+
  geom_line(aes(y=sp1, x=x, col="0.001"), size=1.2)+
  geom_line(aes(y=sp2, x=x, col="1"), size=1.2)+
  geom_line(aes(y=sp3, x=x, col="10"), size=1.2)+
  scale_color_manual(values = c("#5DDEDE", "#FAD74B" ,"#FA6767"),
                     labels= factor(x=c("A", "B", "C"), levels=c("A", "B", "C"), labels=c("0.001", "1", "10"), ordered=TRUE)
                     , name="Gamma")+
  ggtitle("Varying smoothness penalty (20 knots)")+
    theme(legend.title = element_text(face="bold", size=09),
        legend.text = element_text(size=8),
        legend.position = "bottom",
        plot.title = element_text(size = 11, face="bold") )
  
```

]

---

# Generalized Additive Model

+ Regression models where we fit smoothers (like splines) from our data.
+ Strictly Additive, but smoothers can describe complex relationships.
+ In our case:

$$y= \alpha + \beta f(x) + \epsilon$$
--

<br>
Or more formally (Wood, 2017):

$$ g(\mu i) = Ai\theta + f1(x1) + f2(x2i) + f3(x3i, x4i) + ...$$
Where:
+ $\mu i \equiv E(Y i)$, the expectation of Y
+ $Yi \sim EF(\mu i, \phi i)$, $Yi$ is a response variable, distributed according to exponential family distribution with mean $\mu i$ and shape parameter $\phi$.
+ $Ai$ is a row of the model matrix for any strictly parametric model components with $\theta$ the corresponding parameter vector.
+ $fi$ are smooth functions of the covariates, $xk$, where $k$ is each function basis.

---
# What does that mean for me?

+ Can build regression models with smoother
+ Suited to non-linear, or noisy data
+ Hastie(1985) method uses knot ever point, Wood(2017) uses reduced rank version

--

# mgcv: mixed gam computation vehicle

+ Prof. Simon Wood's package, pretty much the standard
+ Included in base `R` distribution and `ggplot2`s `geom_smooth` uses it

```{r gam}
library(mgcv)
my_gam <- gam(y ~ s(x, bs="cr"), data=dt)
```

+ `s()` control smoothers
+ `bs="cr"` telling it to use cubic regression spline ('basis')
+ Default is 10 knots, but can alter with `k=`
---

# Model Output:
```{r gam2}
summary(my_gam)
```


---
# Check your model:

```{r gam3, eval=FALSE}
gam.check(my_gam)
```

```{r gam3a, echo=FALSE, fig.show= 'hide'}
gam.check(my_gam)
```

---
# Check your model:

```{r gam3b, eval=FALSE}
gam.check(my_gam)
```

```{r gam3c, echo=FALSE}
gam.check(my_gam)
```

---

# Is it any better than linear model?

```{r lmcomp}
my_lm <- lm(y ~ x, data=dt)

anova(my_lm, my_gam)
```

## Yes, yes it is!
---

# Summary

+ Regression models are concerned with explaining one variable: `y`, with another: `x`

+ This relationship is assumed to be linear

+ If your data are not linear, or noisy, a smoother might be appropriate

--

+ Splines are ideal smoothers, and are polynomials joined at 'knot' points

--

+ GAMs are a framework for regressions using smoothers

--

+ `mgcv` is a great package for GAMs with various smoothers available

+ `mgcv` estimates the required smoothing penalty for you

+ `gratia` package is a good visualization tool for GAMs

---
# References and Further reading:

### Simon Wood's comprehensive book:
+ WOOD, S. N. 2017. Generalized Additive Models: An Introduction with R, Second Edition, Florida, USA, CRC Press.

### Noam Ross free online GAM course:
https://noamross.github.io/gams-in-r-course/

<br>

+ HARRELL, F. E., JR. 2001. Regression Modeling Strategies, New York, Springer-Verlag New York.

+ HASTIE, T. & TIBSHIRANI, R. 1986. Generalized Additive Models. Statistical Science, 1, 297-310. 291

+ HASTIE, T., TIBSHIRANI, R. & FRIEDMAN, J. 2009. The Elements of Statistical Learning : Data Mining, Inference, and Prediction, New York, NETHERLANDS, Springer.
